global:
  scrape_interval: {{ shared_services.prometheus.scrape_interval | default('15s') }}
  evaluation_interval: 15s
  external_labels:
    cluster: 'staging'
    environment: '{{ deployment_environment }}'
    server: '{{ server_name }}'

rule_files:
  # Add alerting rules here
  # - "alerting_rules.yml"
  # - "recording_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
      timeout: 10s
      api_version: v2

scrape_configs:
  # === Core Infrastructure Monitoring ===
  
  # Prometheus self-monitoring
  - job_name: 'prometheus'
    scrape_interval: 15s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          service: 'prometheus'
          component: 'metrics-storage'
          tier: 'infrastructure'

  # AlertManager monitoring  
  - job_name: 'alertmanager'
    scrape_interval: 30s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['alertmanager:9093']
        labels:
          service: 'alertmanager'
          component: 'alert-routing'
          tier: 'infrastructure'

  # === Application Services Monitoring ===
  
  # Grafana monitoring
  - job_name: 'grafana'
    scrape_interval: 30s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['grafana:3000']
        labels:
          service: 'grafana'
          component: 'visualization'
          tier: 'application'

  # Docker Registry monitoring
  - job_name: 'docker-registry'
    scrape_interval: 30s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['docker-registry:5000']
        labels:
          service: 'docker-registry'
          component: 'artifact-storage'
          tier: 'application'

  # Nginx Proxy monitoring (if nginx-prometheus-exporter is added)
  - job_name: 'nginx-proxy'
    scrape_interval: 30s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['nginx-proxy:9113']
        labels:
          service: 'nginx-proxy'
          component: 'reverse-proxy'
          tier: 'infrastructure'
    scrape_timeout: 10s

  # === Django Application Monitoring ===
  
  # Django Prometheus middleware metrics
  - job_name: 'beryl3-django-metrics'
    scrape_interval: 30s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['beryl3_staging_webapp:8000']
        labels:
          service: 'beryl3-webapp'
          component: 'django-middleware'
          tier: 'application'
          metrics_type: 'performance'
    scrape_timeout: 10s

  # Custom Beryl3 application metrics  
  - job_name: 'beryl3-application-metrics'
    scrape_interval: 30s
    metrics_path: '/sys/metrics/prometheus/'
    static_configs:
      - targets: ['beryl3_staging_webapp:8000']
        labels:
          service: 'beryl3-webapp'  
          component: 'application-data'
          tier: 'application'
          metrics_type: 'business'
    scrape_timeout: 10s

  # === System & Container Monitoring ===
  
  # Node Exporter (host system metrics)
  - job_name: 'node-exporter'
    scrape_interval: 15s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['node-exporter:9100']
        labels:
          service: 'node-exporter'
          component: 'system-metrics'
          tier: 'infrastructure'
          instance: '{{ ansible_host }}'

  # cAdvisor (all container metrics)
  - job_name: 'cadvisor'
    scrape_interval: 15s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['cadvisor:8080']
        labels:
          service: 'cadvisor'
          component: 'container-metrics'
          tier: 'infrastructure'

  # === Log Pipeline Monitoring ===
  
  # Loki monitoring
  - job_name: 'loki'
    scrape_interval: 30s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['loki:3100']
        labels:
          service: 'loki'
          component: 'log-storage'
          tier: 'infrastructure'

  # Promtail monitoring  
  - job_name: 'promtail'
    scrape_interval: 30s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['promtail:9080']
        labels:
          service: 'promtail'
          component: 'log-shipping'
          tier: 'infrastructure'

  # === External Health Checks ===
  
  # HTTP probes for service availability
  - job_name: 'blackbox-http'
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
      - targets:
        - http://grafana.{{ domain_suffix }}
        - http://prometheus.{{ domain_suffix }}
        - http://registry.{{ domain_suffix }}
        - http://{{ ansible_host }}:3000
        - http://{{ ansible_host }}:9090
        - http://{{ ansible_host }}:5000
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: blackbox-exporter:9115
    scrape_interval: 30s

  # === Service Discovery Monitoring ===
  
  # Docker containers discovery (for future auto-discovery)
  - job_name: 'docker-containers'
    scrape_interval: 30s
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 30s
        port: 8080
    relabel_configs:
      # Only monitor containers with prometheus scraping enabled
      - source_labels: [__meta_docker_container_label_prometheus_scrape]
        action: keep
        regex: true
      # Use container name as job name
      - source_labels: [__meta_docker_container_name]
        target_label: job
        replacement: '${1}'
      # Add container labels
      - source_labels: [__meta_docker_container_label_service_name]
        target_label: service
      - source_labels: [__meta_docker_container_name]
        target_label: container_name
      - source_labels: [__meta_docker_container_id]
        target_label: container_id
        regex: '(.{12})'
        replacement: '${1}'