---
# Infrastructure playbook - deploys shared services and infrastructure components
- name: Deploy Infrastructure Services
  hosts: staging
  become: true
  gather_facts: true
  
  pre_tasks:
    - name: Gather OS facts
      setup:
        gather_subset: min
    
    - name: Create www-data group (Arch Linux)
      group:
        name: www-data
        state: present
      when: ansible_os_family == "Archlinux"
    
    - name: Create docker group (if not exists)
      group:
        name: docker
        state: present
    
    - name: Ensure deployment user exists
      user:
        name: "{{ ansible_user }}"
        shell: /bin/bash
        create_home: true
      when: ansible_user != "root"
    
    - name: Add user to groups (Arch Linux)
      user:
        name: "{{ ansible_user }}"
        groups: wheel,docker,www-data
        append: true
      when: ansible_user != "root" and ansible_os_family == "Archlinux"
    
    - name: Add user to groups (Debian/Ubuntu)
      user:
        name: "{{ ansible_user }}"
        groups: sudo,docker,www-data
        append: true
      when: ansible_user != "root" and ansible_os_family == "Debian"
    
    - name: Ensure required directories exist
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
      loop:
        - "{{ shared_data_path }}"
        - /opt/projects
        - /opt/backups
        - /var/log/applications

  tasks:
    # Install Docker and dependencies
    - name: Install Docker (Arch Linux)
      pacman:
        name:
          - docker
          - docker-compose
        state: present
      when: ansible_os_family == "Archlinux"

    - name: Install Docker (Debian/Ubuntu)
      apt:
        name:
          - docker.io
          - docker-compose
        state: present
        update_cache: true
      when: ansible_os_family == "Debian"

    - name: Install Python Docker dependencies (Arch Linux)
      pacman:
        name:
          - python-requests
          - python-docker
        state: present
      when: ansible_os_family == "Archlinux"

    - name: Install Python Docker dependencies (Debian/Ubuntu)
      apt:
        name:
          - python3-docker
          - python3-requests
        state: present
      when: ansible_os_family == "Debian"

    - name: Start and enable Docker service
      systemd:
        name: docker
        state: started
        enabled: true

    - name: Add deploy user to docker group
      user:
        name: "{{ ansible_user }}"
        groups: docker
        append: true

    # Create infrastructure directories
    - name: Create infrastructure directories
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: "{{ ansible_user }}"
        group: docker
      loop:
        - "{{ shared_data_path }}/nginx/config"
        - "{{ shared_data_path }}/nginx/ssl"
        - "{{ shared_data_path }}/prometheus/data"
        - "{{ shared_data_path }}/prometheus/config"
        - "{{ shared_data_path }}/grafana/data"
        - "{{ shared_data_path }}/grafana/config"
        - "{{ shared_data_path }}/grafana/dashboards"
        - "{{ shared_data_path }}/grafana/provisioning/dashboards"
        - "{{ shared_data_path }}/grafana/provisioning/datasources"
        - "{{ shared_data_path }}/loki/data"
        - "{{ shared_data_path }}/loki/config"
        - "{{ shared_data_path }}/alertmanager/data"
        - "{{ shared_data_path }}/alertmanager/config"
        - "{{ shared_data_path }}/promtail/config"
        - "{{ shared_data_path }}/registry/data"
        - "{{ shared_data_path }}/registry/config"
        - "{{ shared_data_path }}/registry/auth"
        - "{{ shared_data_path }}/blackbox/config"
        - "{{ shared_data_path }}/nginx-exporter/config"
        - /var/www/html/.well-known/acme-challenge

    # Generate service configurations
    - name: Generate Nginx configuration
      template:
        src: ../roles/nginx-proxy/templates/nginx-container.conf.j2
        dest: "{{ shared_data_path }}/nginx/config/default.conf"
        owner: "{{ ansible_user }}"
        group: docker
        mode: '0644'

    - name: Generate Prometheus configuration
      template:
        src: ../roles/shared-monitoring/templates/prometheus.yml.j2
        dest: "{{ shared_data_path }}/prometheus/config/prometheus.yml"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Generate Loki configuration
      template:
        src: ../roles/shared-monitoring/templates/loki.yml.j2
        dest: "{{ shared_data_path }}/loki/config/loki.yml"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Generate Promtail configuration
      template:
        src: ../roles/shared-monitoring/templates/promtail.yml.j2
        dest: "{{ shared_data_path }}/promtail/config/promtail.yml"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Generate Grafana configuration
      template:
        src: ../roles/shared-monitoring/templates/grafana.ini.j2
        dest: "{{ shared_data_path }}/grafana/config/grafana.ini"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Copy Grafana datasources provisioning configuration
      copy:
        src: ../roles/shared-monitoring/files/grafana/provisioning/datasources/datasources.yml
        dest: "{{ shared_data_path }}/grafana/provisioning/datasources/datasources.yml"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Copy Grafana dashboards provisioning configuration
      copy:
        src: ../roles/shared-monitoring/files/grafana/provisioning/dashboards/dashboards.yml
        dest: "{{ shared_data_path }}/grafana/provisioning/dashboards/dashboards.yml"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Copy Grafana dashboard files
      copy:
        src: "{{ item }}"
        dest: "{{ shared_data_path }}/grafana/dashboards/"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker
      loop:
        - ../roles/shared-monitoring/files/grafana/dashboards/infrastructure-overview.json
        - ../roles/shared-monitoring/files/grafana/dashboards/container-monitoring.json
        - ../roles/shared-monitoring/files/grafana/dashboards/service-health.json
        - ../roles/shared-monitoring/files/grafana/dashboards/nginx-performance.json
        - ../roles/shared-monitoring/files/grafana/dashboards/log-analysis.json
        - ../roles/shared-monitoring/files/grafana/dashboards/alert-management.json
        - ../roles/shared-monitoring/files/grafana/dashboards/grafana-django-logs-dashboard.json
        - ../roles/shared-monitoring/files/grafana/dashboards/grafana-django-metrics-dashboard.json

    - name: Generate AlertManager configuration
      template:
        src: ../roles/shared-monitoring/templates/alertmanager.yml.j2
        dest: "{{ shared_data_path }}/alertmanager/config/alertmanager.yml"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Generate Registry configuration
      copy:
        content: |
          version: 0.1
          log:
            fields:
              service: registry
          storage:
            cache:
              blobdescriptor: inmemory
            filesystem:
              rootdirectory: /var/lib/registry
          http:
            addr: :5000
            headers:
              X-Content-Type-Options: [nosniff]
              Access-Control-Allow-Origin: ['http://192.168.1.14:8082']
              Access-Control-Allow-Methods: ['HEAD', 'GET', 'OPTIONS', 'DELETE']
              Access-Control-Allow-Headers: ['Authorization', 'Accept', 'Cache-Control']
              Access-Control-Max-Age: [1728000]
              Access-Control-Allow-Credentials: [true]
              Access-Control-Expose-Headers: ['Docker-Content-Digest']
          auth:
            htpasswd:
              realm: basic-realm
              path: /auth/htpasswd
          health:
            storagedriver:
              enabled: true
              interval: 10s
              threshold: 3
        dest: "{{ shared_data_path }}/registry/config/config.yml"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Generate registry htpasswd file
      shell: |
        echo "registry:$(openssl passwd -6 '{{ registry_password | default("registry123") }}')" > {{ shared_data_path }}/registry/auth/htpasswd
        chown {{ ansible_user }}:docker {{ shared_data_path }}/registry/auth/htpasswd
        chmod 644 {{ shared_data_path }}/registry/auth/htpasswd
      args:
        creates: "{{ shared_data_path }}/registry/auth/htpasswd"

    - name: Generate Blackbox Exporter configuration
      copy:
        content: |
          modules:
            http_2xx:
              prober: http
              timeout: 5s
              http:
                valid_http_versions: ["HTTP/1.1", "HTTP/2.0"]
                valid_status_codes: [200]
                method: GET
                headers:
                  Host: {{ beryl3_app.domain | default('beryl3-stage.mdubiel.org') }}
                  Accept-Language: en-US
                preferred_ip_protocol: "ip4"
                ip_protocol_fallback: false
                fail_if_ssl: false
                fail_if_not_ssl: false
                tls_config:
                  insecure_skip_verify: false
                basic_auth:
                  username: ""
                  password: ""
            
            http_post_2xx:
              prober: http
              timeout: 5s
              http:
                method: POST
                headers:
                  Content-Type: application/json
                body: '{}'
            
            tcp_connect:
              prober: tcp
              timeout: 5s
            
            dns:
              prober: dns
              timeout: 5s
              dns:
                query_name: "{{ beryl3_app.domain | default('beryl3-stage.mdubiel.org') }}"
                query_type: "A"
                valid_rcodes:
                  - NOERROR
                validate_answer_rrs:
                  fail_if_matches_regexp:
                    - ".*127.0.0.1"
                  fail_if_not_matches_regexp:
                    - "www.prometheus.io.\t300\tIN\tA\t46.101.152.148"
        dest: "{{ shared_data_path }}/blackbox/config/blackbox.yml"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    - name: Generate Nginx stub_status configuration
      copy:
        content: |
          server {
              listen 8081;
              server_name localhost;
              
              location /nginx_status {
                  stub_status;
                  access_log off;
                  allow 127.0.0.1;
                  allow 172.16.0.0/12;
                  deny all;
              }
              
              location / {
                  return 404;
              }
          }
        dest: "{{ shared_data_path }}/nginx/config/status.conf"
        mode: '0644'
        owner: "{{ ansible_user }}"
        group: docker

    # Set correct permissions for data directories
    - name: Fix data directory permissions
      file:
        path: "{{ item.path }}"
        owner: "{{ item.owner }}"
        group: "{{ item.group }}"
        mode: "{{ item.mode }}"
        state: directory
        recurse: true
      loop:
        - { path: "{{ shared_data_path }}/grafana/data", owner: "472", group: "472", mode: "0755" }
        - { path: "{{ shared_data_path }}/prometheus/data", owner: "65534", group: "65534", mode: "0755" }
        - { path: "{{ shared_data_path }}/loki/data", owner: "10001", group: "10001", mode: "0755" }
        - { path: "{{ shared_data_path }}/registry/data", owner: "{{ ansible_user }}", group: "docker", mode: "0755" }

    # Create Docker networks
    - name: Create Docker networks
      community.docker.docker_network:
        name: "{{ item }}"
        state: present
      loop:
        - monitoring
        - projects
        - registry

    # Pull Docker images
    - name: Pull infrastructure Docker images
      community.docker.docker_image:
        name: "{{ item }}"
        source: pull
        state: present
      loop:
        - nginx:alpine
        - prom/prometheus:latest
        - grafana/grafana:latest
        - grafana/loki:latest
        - prom/alertmanager:latest
        - prom/node-exporter:latest
        - gcr.io/cadvisor/cadvisor:latest
        - grafana/promtail:latest
        - registry:2
        - prom/blackbox-exporter:latest
        - nginx/nginx-prometheus-exporter:latest
        - joxit/docker-registry-ui:2.0
        - adminer:latest

    # Start infrastructure containers
    - name: Start nginx-proxy container
      community.docker.docker_container:
        name: nginx-proxy
        image: nginx:alpine
        state: started
        restart_policy: unless-stopped
        ports:
          - "80:80"
          - "443:443"
          - "8081:8081"
        volumes:
          - "{{ shared_data_path }}/nginx/config:/etc/nginx/conf.d:ro"
          - "{{ shared_data_path }}/nginx/ssl:/etc/nginx/ssl:ro"
          - "/opt/ssl:/etc/ssl:ro"
        labels:
          prometheus.scrape: "false"
          service.name: "nginx-proxy"
          service.component: "reverse-proxy"
        networks:
          - name: monitoring
          - name: projects
          - name: registry

    - name: Start Docker Registry container
      community.docker.docker_container:
        name: docker-registry
        image: registry:2
        state: started
        restart_policy: unless-stopped
        ports:
          - "{{ registry_port | default(5000) }}:5000"
        volumes:
          - "{{ shared_data_path }}/registry/data:/var/lib/registry"
          - "{{ shared_data_path }}/registry/config:/etc/docker/registry:ro"
          - "{{ shared_data_path }}/registry/auth:/auth:ro"
        env:
          REGISTRY_CONFIG_PATH: /etc/docker/registry/config.yml
        labels:
          prometheus.scrape: "true"
          service.name: "docker-registry"
          service.component: "artifact-storage"
        networks:
          - name: registry
          - name: monitoring

    - name: Start Prometheus container
      community.docker.docker_container:
        name: prometheus
        image: prom/prometheus:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "{{ shared_services.prometheus.port }}:9090"
        volumes:
          - "{{ shared_data_path }}/prometheus/config:/etc/prometheus:ro"
          - "{{ shared_data_path }}/prometheus/data:/prometheus"
        command: >
          --config.file=/etc/prometheus/prometheus.yml
          --storage.tsdb.path=/prometheus
          --storage.tsdb.retention.time={{ shared_services.prometheus.retention_time }}
          --web.console.libraries=/usr/share/prometheus/console_libraries
          --web.console.templates=/usr/share/prometheus/consoles
          --web.enable-lifecycle
          --web.enable-admin-api
        networks:
          - name: monitoring

    - name: Start Grafana container
      community.docker.docker_container:
        name: grafana
        image: grafana/grafana:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "{{ shared_services.grafana.port }}:3000"
        volumes:
          - "{{ shared_data_path }}/grafana/data:/var/lib/grafana"
          - "{{ shared_data_path }}/grafana/config/grafana.ini:/etc/grafana/grafana.ini:ro"
          - "{{ shared_data_path }}/grafana/provisioning:/etc/grafana/provisioning:ro"
          - "{{ shared_data_path }}/grafana/dashboards:/var/lib/grafana/dashboards:ro"
        env:
          GF_SECURITY_ADMIN_USER: "{{ shared_services.grafana.admin_user }}"
          GF_SECURITY_ADMIN_PASSWORD: "{{ shared_services.grafana.admin_password }}"
        labels:
          prometheus.scrape: "true"
          service.name: "grafana"
          service.component: "visualization"
        networks:
          - name: monitoring

    - name: Start Loki container
      community.docker.docker_container:
        name: loki
        image: grafana/loki:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "{{ shared_services.loki.port }}:3100"
        volumes:
          - "{{ shared_data_path }}/loki/config:/etc/loki:ro"
          - "{{ shared_data_path }}/loki/data:/tmp/loki"
        command: -config.file=/etc/loki/loki.yml
        networks:
          - name: monitoring

    - name: Start AlertManager container
      community.docker.docker_container:
        name: alertmanager
        image: prom/alertmanager:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "{{ shared_services.alertmanager.port }}:9093"
        volumes:
          - "{{ shared_data_path }}/alertmanager/config:/etc/alertmanager:ro"
          - "{{ shared_data_path }}/alertmanager/data:/alertmanager"
        networks:
          - name: monitoring

    - name: Start Node Exporter container
      community.docker.docker_container:
        name: node-exporter
        image: prom/node-exporter:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "{{ shared_services.node_exporter.port }}:9100"
        command: >
          --path.procfs=/host/proc
          --path.sysfs=/host/sys
          --path.rootfs=/host
          --collector.filesystem.mount-points-exclude='^/(sys|proc|dev|host|etc)($$|/)'
        volumes:
          - "/proc:/host/proc:ro"
          - "/sys:/host/sys:ro"
          - "/:/host:ro"
        networks:
          - name: monitoring

    - name: Start cAdvisor container
      community.docker.docker_container:
        name: cadvisor
        image: gcr.io/cadvisor/cadvisor:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "8080:8080"
        volumes:
          - "/:/rootfs:ro"
          - "/var/run:/var/run:rw"
          - "/sys:/sys:ro"
          - "/var/lib/docker/:/var/lib/docker:ro"
        networks:
          - name: monitoring

    - name: Start Promtail container
      community.docker.docker_container:
        name: promtail
        image: grafana/promtail:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "{{ shared_services.promtail.port }}:9080"
        volumes:
          - "{{ shared_data_path }}/promtail/config:/etc/promtail:ro"
          - "/var/log:/var/log:ro"
        command: -config.file=/etc/promtail/promtail.yml
        labels:
          prometheus.scrape: "true"
          service.name: "promtail"
          service.component: "log-shipping"
        networks:
          - name: monitoring

    - name: Start Blackbox Exporter container
      community.docker.docker_container:
        name: blackbox-exporter
        image: prom/blackbox-exporter:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "9115:9115"
        volumes:
          - "{{ shared_data_path }}/blackbox/config:/config:ro"
        command: --config.file=/config/blackbox.yml
        labels:
          prometheus.scrape: "true"
          service.name: "blackbox-exporter"
          service.component: "health-probes"
        networks:
          - name: monitoring

    - name: Start Nginx Prometheus Exporter container
      community.docker.docker_container:
        name: nginx-prometheus-exporter
        image: nginx/nginx-prometheus-exporter:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "9113:9113"
        command: --nginx.scrape-uri=http://nginx-proxy:8081/nginx_status
        labels:
          prometheus.scrape: "true"
          service.name: "nginx-prometheus-exporter"
          service.component: "nginx-metrics"
        networks:
          - name: monitoring

    - name: Start Docker Registry UI container
      community.docker.docker_container:
        name: docker-registry-ui
        image: joxit/docker-registry-ui:2.0
        state: started
        restart_policy: unless-stopped
        ports:
          - "8082:80"
        env:
          REGISTRY_URL: http://192.168.1.14:5000
          REGISTRY_TITLE: "Beryl3 Registry"
          DELETE_IMAGES: "true"
          SHOW_CONTENT_DIGEST: "true"
          NGINX_PROXY_PASS_URL: http://192.168.1.14:5000
          SINGLE_REGISTRY: "true"
          SHOW_CATALOG_NB_TAGS: "true"
          CATALOG_ELEMENTS_LIMIT: "1000"
          REGISTRY_USERNAME: "registry"
          REGISTRY_PASSWORD: "registry123"
        labels:
          prometheus.scrape: "false"
          service.name: "docker-registry-ui"
          service.component: "registry-interface"
        networks:
          - name: registry
          - name: monitoring

    - name: Start Adminer PostgreSQL Management container
      community.docker.docker_container:
        name: adminer
        image: adminer:latest
        state: started
        restart_policy: unless-stopped
        ports:
          - "8084:8080"
        env:
          ADMINER_DEFAULT_SERVER: "postgres"
          ADMINER_DESIGN: "pepa-linha"
        labels:
          prometheus.scrape: "false"
          service.name: "adminer"
          service.component: "database-management"
        networks:
          - name: monitoring
          - name: projects

  post_tasks:
    - name: Verify infrastructure containers are running
      community.docker.docker_container_info:
        name: "{{ item }}"
      register: container_status
      loop:
        - nginx-proxy
        - docker-registry
        - docker-registry-ui
        - prometheus
        - grafana
        - loki
        - alertmanager
        - node-exporter
        - cadvisor
        - promtail
        - blackbox-exporter
        - nginx-prometheus-exporter
        - adminer
      tags: ['verify']
    
    - name: Display infrastructure container status
      debug:
        msg: "{{ item.container.Name }} is {{ item.container.State.Status }}"
      loop: "{{ container_status.results }}"
      when: item.exists
      tags: ['verify']
    
    - name: Display registry information
      debug:
        msg: |
          Docker Registry is available at:
          - Internal: http://docker-registry:5000
          - External: http://{{ ansible_host }}:{{ registry_port | default(5000) }}
          - Web UI: http://{{ ansible_host }}:8082 (Visual Interface)
          - Credentials: registry / {{ registry_password | default("registry123") }}
          - Image Namespace: mdubiel.org
      tags: ['verify']
    
    - name: Display monitoring information
      debug:
        msg: |
          === Monitoring Stack Information ===
          
          üìä Core Monitoring:
          - Prometheus: http://{{ ansible_host }}:9090 | http://prometheus.{{ domain_suffix }}
          - Grafana: http://{{ ansible_host }}:3000 | http://grafana.{{ domain_suffix }}
            ‚îî‚îÄ‚îÄ Admin: admin / {{ shared_services.grafana.admin_password }}
          - AlertManager: http://{{ ansible_host }}:9093
          
          üìà Metrics Exporters:
          - Node Exporter: http://{{ ansible_host }}:9100/metrics (system metrics)
          - cAdvisor: http://{{ ansible_host }}:8080 (container metrics)
          - Nginx Exporter: http://{{ ansible_host }}:9113/metrics (nginx metrics)
          - Blackbox Exporter: http://{{ ansible_host }}:9115 (health probes)
          
          üóÑÔ∏è Database Management:
          - Adminer: http://{{ ansible_host }}:8084 (PostgreSQL management)
          
          üìã Log Pipeline:
          - Loki: http://{{ ansible_host }}:3100 (log storage)
          - Promtail: http://{{ ansible_host }}:9080/metrics (log shipping)
          
          üîç Monitored Targets ({{ monitoring_targets_count | default('13') }} total):
          1. prometheus (self-monitoring)
          2. alertmanager (alert routing)
          3. grafana (dashboards)
          4. docker-registry (artifacts)
          5. docker-registry-ui (registry interface)
          6. nginx-proxy (reverse proxy via exporter)
          7. node-exporter (host system)
          8. cadvisor (all containers)
          9. loki (log storage)
          10. promtail (log shipping)
          11. blackbox-exporter (health checks)
          12. nginx-prometheus-exporter (nginx metrics)
          13. adminer (postgresql management)
          
          üåê Health Check URLs:
          - All services monitored via blackbox-exporter
          - External domain checks for *.{{ domain_suffix }}
          - Internal service health via /metrics endpoints
          
          ‚ö° Auto-Discovery:
          - Docker container discovery enabled
          - Labels: prometheus.scrape=true for auto-inclusion
          - Service discovery via Docker socket
      tags: ['verify']